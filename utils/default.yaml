# TA-A-GEM Configuration File
# Default parameters for incremental learning experiments

# Task Configuration
task_type: "rotation" # Options: permutation, rotation, class_split
lite: false # Quick test mode with fewer tasks and data
show_images: true # Whether to show images
output_dir: "./test_results" # Where to put any output files
experiment_name: "Unnamed"

# Dataset Configuration
dataset_name: "mnist" # Dataset to use: mnist or fashion_mnist
num_classes: 10 # For MNIST
input_dim: 784 # For MNIST (28*28)

# Model Configuration
hidden_dim: 200 # Hidden layer dimension as per paper
device: "cuda" # Device to use. "cuda" for GPU, "cpu" for CPU.
random_em: false # Fetch randomly from episodic memory instead of getting all samples


# Memory Configuration
memory_size_q: 10 # Number of clusters per pool (Q), overridden below
memory_size_p: 3 # Max samples per cluster (P) - as per paper

# Training Configuration
batch_size: 10 # Batch size for training (overridden to 50 in lite mode)
learning_rate: 0.001 # Initial learning rate
num_epochs: 20 # Number of epochs per task
# num_tasks: 5 # Number of tasks (overridden to 2 in lite mode)

# Learning Rate Scheduler
use_learning_rate_scheduler: true # Use adaptive learning rate scheduler

# Task Configuration
task_specific:
  permutation:
    num_tasks: 10
    num_pools: 10
    clusters_per_pool: 10
  rotation:
    num_tasks: 10
    num_pools: 10
    clusters_per_pool: 10
  class_split:
    num_tasks: 5
    num_pools: 2
    clusters_per_pool: 50

# Removal method
removal: 'remove_random'
# Options:
    # 'remove_oldest'
    # 'remove_furthest_from_mean'
    # 'remove_random'
    # 'remove_furthest_from_new'
    # 'remove_based_on_mean'
    # 'remove_closest_to_new'
    # 'remove_by_weighted_mean_distance'
    # 'remove_by_log_weighted_mean_distance'
    # 'remove_oldest_with_distance_override'
consider_newest: false # Do you want to be able to remove the newest sample?


# Scrambling of epochs
# It'll be totally random
task_introduction: 'half and half'
# Options:
  # 'sequential' - 20 epochs per task, introduced in sequence
  # 'half and half' - 10 epochs per task in sequence, then 10 epochs each again in sequence
  # 'random' - 20 epochs per task total, but the program will decide the order.
  # 'continual change' - tasks are largely sequential, but blended together. Lamers core